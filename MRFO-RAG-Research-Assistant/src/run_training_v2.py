"""
ä½¿ç”¨LLaMA-Factoryå¾®è°ƒMRFOä¸“å®¶æ¨¡å‹ - æ”¹è¿›ç‰ˆ
å¢å¼ºè®­ç»ƒå‚æ•°,æå‡å¾®è°ƒæ•ˆæœ
"""
import os
import torch

def check_environment():
    """æ£€æŸ¥ç¯å¢ƒ"""
    print("=" * 70)
    print("ğŸ” ç¯å¢ƒæ£€æŸ¥")
    print("=" * 70)

    # GPU
    if torch.cuda.is_available():
        print(f"âœ… GPU: {torch.cuda.get_device_name(0)}")
        print(f"   æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB")
    else:
        print("âš ï¸  æœªæ£€æµ‹åˆ°GPU,å°†ä½¿ç”¨CPU(ä¼šå¾ˆæ…¢)")

    # æ•°æ®
    if os.path.exists("mrfo_training_data_complete.json"):
        import json
        with open("mrfo_training_data_complete.json", encoding='utf-8') as f:  # â¬…ï¸ ä¿®å¤ç¼–ç 
            data = json.load(f)
        print(f"âœ… è®­ç»ƒæ•°æ®: {len(data)} æ¡")
    else:
        print("âŒ æœªæ‰¾åˆ°è®­ç»ƒæ•°æ®æ–‡ä»¶!")
        return False

    # LLaMA-Factory
    try:
        from llamafactory.train.tuner import run_exp
        print("âœ… LLaMA-Factoryå·²å®‰è£…")
    except ImportError:
        print("âŒ LLaMA-Factoryæœªå®‰è£…!")
        print("   è¯·è¿è¡Œ: pip install llamafactory")
        return False

    print("=" * 70)
    return True


def train(config_level="balanced"):
    """
    æ‰§è¡Œè®­ç»ƒ

    Args:
        config_level: é…ç½®çº§åˆ«
            - "quick": å¿«é€Ÿæ”¹è¿›(5è½®,å­¦ä¹ ç‡8e-5)
            - "balanced": å¹³è¡¡æ”¹è¿›(8è½®,å­¦ä¹ ç‡1e-4) [æ¨è]
            - "aggressive": æ¿€è¿›æ”¹è¿›(10è½®,å­¦ä¹ ç‡1.5e-4)
    """
    from llamafactory.train.tuner import run_exp

    print("\n" + "=" * 70)
    print(f"ğŸš€ å¼€å§‹å¾®è°ƒMRFOä¸“å®¶æ¨¡å‹ - {config_level.upper()}æ¨¡å¼")
    print("=" * 70)
    print()

    # æ ¹æ®é…ç½®çº§åˆ«è®¾ç½®å‚æ•°
    if config_level == "quick":
        epochs = 30
        lr = 5e-4
        lora_rank = 16
        lora_alpha = 32
        grad_accum = 8
        warmup = 0.15
        print("ğŸ“‹ é…ç½®: å¿«é€Ÿæ”¹è¿›")
        print("   - é€‚åˆ: æ•ˆæœç•¥æœ‰æ”¹å–„ä½†ä¸å¤Ÿæ˜æ˜¾")
        print("   - é¢„è®¡æ—¶é—´: 12-15åˆ†é’Ÿ")

    elif config_level == "aggressive":
        epochs = 10
        lr = 1.5e-4
        lora_rank = 32
        lora_alpha = 64
        grad_accum = 8
        warmup = 0.2
        print("ğŸ“‹ é…ç½®: æ¿€è¿›æ”¹è¿›")
        print("   - é€‚åˆ: ç¡®ä¿å®Œå…¨è®°ä½æ‰€æœ‰è®­ç»ƒæ•°æ®")
        print("   - é¢„è®¡æ—¶é—´: 35-40åˆ†é’Ÿ")
        print("   âš ï¸  æ˜¾å­˜å¯èƒ½æ¥è¿‘4GBä¸Šé™")

    else:  # balanced (é»˜è®¤æ¨è)
        epochs = 8
        lr = 1e-4
        lora_rank = 16
        lora_alpha = 32
        grad_accum = 8
        warmup = 0.15
        print("ğŸ“‹ é…ç½®: å¹³è¡¡æ”¹è¿› [æ¨è]")
        print("   - é€‚åˆ: å¤§å¤šæ•°æƒ…å†µ")
        print("   - é¢„è®¡æ—¶é—´: 20-25åˆ†é’Ÿ")

    # è®­ç»ƒå‚æ•°
    args = {
        # æ¨¡å‹
        "model_name_or_path": "Qwen/Qwen2.5-1.5B-Instruct",
        "quantization_bit": 4,
        "quantization_method": "bitsandbytes",

        # LoRA (æ”¹è¿›)
        "finetuning_type": "lora",
        "lora_rank": lora_rank,           # â¬…ï¸ ä»8æ”¹ä¸º16/32
        "lora_alpha": lora_alpha,         # â¬…ï¸ ä»16æ”¹ä¸º32/64
        "lora_dropout": 0.05,
        "lora_target": "all",

        # æ•°æ®
        "dataset": "mrfo_dataset",
        "dataset_dir": "./",
        "template": "qwen",
        "cutoff_len": 512,
        "val_size": 0.1,
        "overwrite_cache": True,

        # è®­ç»ƒ (æ”¹è¿›)
        "stage": "sft",
        "do_train": True,
        "output_dir": f"./saves/mrfo_lora_{config_level}",  # ä¸åŒé…ç½®ä¿å­˜åˆ°ä¸åŒæ–‡ä»¶å¤¹
        "overwrite_output_dir": True,

        "per_device_train_batch_size": 1,
        "gradient_accumulation_steps": grad_accum,  # â¬…ï¸ ä»4æ”¹ä¸º8
        "learning_rate": lr,                        # â¬…ï¸ ä»5e-5æ”¹ä¸ºæ›´é«˜
        "num_train_epochs": epochs,                 # â¬…ï¸ ä»3æ”¹ä¸º5/8/10

        "optim": "adamw_torch",
        "lr_scheduler_type": "cosine",
        "warmup_ratio": warmup,                     # â¬…ï¸ ä»0.1æ”¹ä¸º0.15/0.2

        "logging_steps": 5,
        "save_steps": 50,
        "save_total_limit": 2,

        "fp16": True,
        "report_to": "none",
        "seed": 42,
    }

    print(f"\nğŸ“Š è¯¦ç»†é…ç½®:")
    print(f"   æ¨¡å‹: Qwen2.5-1.5B-Instruct")
    print(f"   æ•°æ®: 56æ¡")
    print(f"   è®­ç»ƒè½®æ•°: {epochs} epochs")
    print(f"   å­¦ä¹ ç‡: {lr}")
    print(f"   LoRA Rank: {lora_rank}")
    print(f"   Batch size: 1 Ã— {grad_accum}(ç´¯ç§¯) = {grad_accum}")
    print(f"   Warmup: {warmup*100:.0f}%")
    print()

    try:
        # æ‰§è¡Œè®­ç»ƒ
        run_exp(args)

        print("\n" + "=" * 70)
        print("âœ… è®­ç»ƒå®Œæˆ!")
        print("=" * 70)
        print(f"ğŸ“ æ¨¡å‹ä¿å­˜åœ¨: ./saves/mrfo_lora_{config_level}")
        print()
        print("ğŸ’¡ æŸ¥çœ‹è®­ç»ƒæ•ˆæœ:")
        print("   - å¦‚æœLoss < 1.5: åŸºæœ¬æˆåŠŸ")
        print("   - å¦‚æœLoss < 1.0: å¾ˆå¥½")
        print("   - å¦‚æœLoss < 0.5: å®Œç¾!")

    except Exception as e:
        print(f"\nâŒ è®­ç»ƒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


def main():
    # 1. æ£€æŸ¥ç¯å¢ƒ
    if not check_environment():
        return

    # 2. é€‰æ‹©é…ç½®çº§åˆ«
    print("\n" + "=" * 70)
    print("ğŸ›ï¸  é€‰æ‹©è®­ç»ƒé…ç½®")
    print("=" * 70)
    print()
    print("1. å¿«é€Ÿæ”¹è¿› (5è½®, ~15åˆ†é’Ÿ)")
    print("   - é€‚åˆ: ç¬¬ä¸€æ¬¡å¾®è°ƒæ•ˆæœç•¥æœ‰æ”¹å–„")
    print("   - Lossç›®æ ‡: < 1.5")
    print()
    print("2. å¹³è¡¡æ”¹è¿› (8è½®, ~25åˆ†é’Ÿ) [â­æ¨è]")
    print("   - é€‚åˆ: å¤§å¤šæ•°æƒ…å†µ,æˆåŠŸç‡é«˜")
    print("   - Lossç›®æ ‡: < 1.0")
    print()
    print("3. æ¿€è¿›æ”¹è¿› (10è½®, ~40åˆ†é’Ÿ)")
    print("   - é€‚åˆ: ç¡®ä¿å®Œå…¨è®°ä½è®­ç»ƒæ•°æ®")
    print("   - Lossç›®æ ‡: < 0.5")
    print("   - æ³¨æ„: æ˜¾å­˜å ç”¨æ¥è¿‘4GB")
    print()

    choice = input("è¯·é€‰æ‹©é…ç½® (1/2/3, é»˜è®¤2): ").strip()

    config_map = {
        "1": "quick",
        "2": "balanced",
        "3": "aggressive",
        "": "balanced"  # é»˜è®¤
    }

    config_level = config_map.get(choice, "balanced")

    # 3. ç¡®è®¤å¼€å§‹
    print("\n" + "=" * 70)
    print(f"å‡†å¤‡å¼€å§‹è®­ç»ƒ - {config_level.upper()}æ¨¡å¼")
    print("=" * 70)
    print()
    print("è®­ç»ƒè¿‡ç¨‹ä¸­ä½ ä¼šçœ‹åˆ°:")
    print("  âœ… Lossé€æ¸ä¸‹é™")
    print("  âœ… æ˜¾å­˜å ç”¨ç¨³å®š")
    print("  â±ï¸  è¿›åº¦æ¡æ˜¾ç¤ºå‰©ä½™æ—¶é—´")
    print()

    input("æŒ‰Enterå¼€å§‹è®­ç»ƒ...")

    # 4. å¼€å§‹è®­ç»ƒ
    train(config_level)

    print("\n" + "=" * 70)
    print("ğŸ¯ ä¸‹ä¸€æ­¥: æµ‹è¯•å¾®è°ƒæ•ˆæœ")
    print("=" * 70)
    print()
    print("è¿è¡Œæµ‹è¯•:")
    print(f"   python test_finetuned_model.py")
    print()
    print("æ³¨æ„: æµ‹è¯•æ—¶éœ€è¦ä¿®æ”¹æ¨¡å‹è·¯å¾„ä¸º:")
    print(f"   lora_path = './saves/mrfo_lora_{config_level}'")


if __name__ == "__main__":
    main()